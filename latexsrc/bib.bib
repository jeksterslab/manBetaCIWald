% Encoding: US-ASCII

@Book{
	nas1982,
	author    = {
		{National Research Council}.
	},
	date      = {
		1982
	},
	title     = {
		An assessment of research-doctorate programs in the {United States}: Social and behavioral sciences
	},
	location  = {
		Washington, D.C.
	},
	publisher = {
		National Academies Press
	},
}

@Comment{jabref-meta: databaseType:biblatex;}
% Encoding: US-ASCII

@Book{
	Lib-Nonnormality-Bradley-1968,
	author    = {
		Bradley, James V.
	},
	date      = {
		1968
	},
	title     = {
		Distribution free statistical tests
	},
	location  = {
		Englewood Cliffs, NJ
	},
	publisher = {
		Prentice-Hall
	},
}

@Article{
	Lib-Nonnormality-Glass-1972
	,
	author       = {
		Glass, Gene V.
		and
		Peckham, Percy D.
		and
		Sanders, James R.
	},
	date         = {
		1972-09
	},
	journaltitle = {
		Review of Educational Research
	},
	title        = {
		Consequences of failure to meet assumptions underlying the fixed effects analyses of variance and covariance
	},
	doi          = {
		10.3102/00346543042003237
	},
	number       = {
		3
	},
	pages        = {
		237--288
	},
	volume       = {
		42
	},
	publisher    = {
		American Educational Research Association ({AERA})
	},
}

@Article{
	Lib-Nonnormality-Pearson-1975
	,
	author       = {
		Pearson, E. S.
		and
		Please, N. W.
	},
	date         = {
		1975-08
	},
	journaltitle = {
		Biometrika
	},
	title        = {
		Relation between the shape of population distribution and the robustness of four simple test statistics
	},
	doi          = {
		10.1093/biomet/62.2.223
	},
	number       = {
		2
	},
	pages        = {
		223--241
	},
	volume       = {
		62
	},
	publisher    = {
		Oxford University Press ({OUP})
	},
	abstract     = {
		The underlying theory upon which a great number of statistical procedures are based assumes that the variable or variables sampled are normally distributed.
		While there has been a good deal of theoretical research on the robustness of these procedures,
		the results seem not to have been set out in terms which the unsophisticated user of statistical methods can easily assimilate.
		The present paper, based on extensive computer simulation, aims at relating diagrammatically the shape of population to the robustness of the distribution of four simple statistics.
		A set of 29 Johnson SB and SU curves, several Pearson and Weibull curves and some large-sample histograms have been used as populations. The results indicate the extent to which the population moment ratios $\sqrt{\beta 1}$ and $\sqrt{\beta 2}$ determine the degree of robustness; charts are provided which should help the user, if he has some knowledge of these two parameters, to decide whether the lack of robustness matters from the practical aspect with which he is concerned.
	},
}

@Article{
	Lib-Nonnormality-Blair-1981
	,
	author       = {
		Blair, R. Clifford
	},
	date         = {
		1981-12
	},
	journaltitle = {
		Review of Educational Research
	},
	title        = {
		A reaction to ``Consequences of failure to meet assumptions underlying the fixed effects analysis of variance and covariance''
	},
	doi          = {
		10.3102/00346543051004499
	},
	number       = {
		4
	},
	pages        = {
		499--507
	},
	volume       = {
		51
	},
	publisher    = {
		American Educational Research Association ({AERA})
	},
	abstract     = {
		Glass, Peckham, and Sanders discourage the use of nonparametric counterparts of the $t$-test even when it is known that data were sampled from non-normal (e.g., highly skewed) distributions.
		This paper contends that Glass et al. erred in taking this position and that their error was due,
		at least in part,
		to their failure to consider the relative power of the $t$-test and its nonparametric counterparts under various population shapes.
		It is further contended that Wilcoxon’s rank-sum test has power properties that make it preferable to the $t$-test in many, perhaps even most,
		non-normal population situations.
	},
}

@Article{
	Lib-Nonnormality-Bradley-1982
	,
	author       = {
		Bradley, James V.
	},
	date         = {
		1982-08
	},
	journaltitle = {
		Bulletin of the Psychonomic Society
	},
	title        = {
		The insidious {L}-shaped distribution
	},
	doi          = {
		10.3758/bf03330089
	},
	number       = {
		2
	},
	pages        = {
		85--88
	},
	volume       = {
		20
	},
	publisher    = {
		Springer Science and Business Media {LLC}
	},
	abstract     = {
		L-shaped distributions are not rare and are probably far more prevalent than is generally realized.
		They are highly conducive to nonrobustness of normality-assuming statistical tests, and they strongly resist transformation to normality.
		The thinner the tail of the distribution, the more unlikely it is that its L-shapedness will be detected by inspecting a sample drawn from it.
		Yet, as the tail of an L-shaped distribution becomes increasingly shallow, its skewness and kurtosis depart increasingly from their ``normal-distribution'' values, and the distribution becomes increasingly conducive to drastic nonrobustness.
		Worse, a fairly common type of experimental situation in psychological research produces shallow-tailed L-shaped distributions.
	},
}

@Article{
	Lib-Nonnormality-Micceri-1989
	,
	author       = {
		Micceri, Theodore
	},
	date         = {
		1989
	},
	journaltitle = {
		Psychological Bulletin
	},
	title        = {
		The unicorn, the normal curve, and other improbable creatures
	},
	doi          = {
		10.1037/0033-2909.105.1.156
	},
	number       = {
		1
	},
	pages        = {
		156--166
	},
	volume       = {
		105
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	abtsract = {
		An investigation of the distributional characteristics of 440 large-sample achievement and psychometric measures found all to be significantly nonnormal at the alpha .01 significance level.
		Several classes of contamination were found,
		including tail weights from the uniform to the double exponential,
		exponential-level asymmetry,
		severe digit preferences,
		multimodalities,
		and modes external to the mean/median interval.
		Thus,
		the underlying tenets of normality-assuming statistics appear fallacious for these commonly used types of data.
		However,
		findings here also fail to support the types of distributions used in most prior robustness research suggesting the failure of such statistics under nonnormal conditions.
		A reevaluation of the statistical robustness literature appears appropriate in light of these findings.
	},
}

@Article{
	Lib-Nonnormality-Sawilowsky-1992
	,
	author       = {
		Sawilowsky, Shlomo S. 
		and 
		Blair, R. Clifford
	},
	date         = {
		1992
	},
	journaltitle = {
		Psychological Bulletin
	},
	title        = {
		A more realistic look at the robustness and {Type II} error properties of the t test to departures from population normality
	},
	doi          = {
		10.1037/0033-2909.111.2.352
	},
	number       = {
		2
	},
	pages        = {
		352--360
	},
	volume       = {
		111
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	abstract     = {
		The Type I and II error properties of the t test were evaluated by means of a Monte Carlo study that sampled 8 real distribution shapes identified by T. Micceri (1986, 1989) as being representative of types encountered in psychology and education research.
		Results showed the independent-samples t tests to be reasonably robust to Type I error when (1) sample sizes are equal, (2) sample sizes are fairly large, and (3) tests are 2-tailed rather than 1-tailed. 
		Nonrobust results were obtained primarily under distributions with extreme skew.
		The t test was robust to Type II error under these nonnormal distributions,
		but researchers should not overlook robust nonparametric competitors that are often more powerful than the t test when its underlying assumptions are violated.
	},
}

@Article{
	Lib-Nonnormality-Blanca-2013
	,
	author       = {
		Blanca, Mar{\'{\i}}a J. 
		and 
		Arnau, Jaume 
		and 
		L{\'{o}}pez-Montiel, Dolores 
		and 
		Bono, Roser 
		and 
		Bendayan, Rebecca
	},
	date         = {
		2013-05
	},
	journaltitle = {
		Methodology
	},
	title        = {
		Skewness and kurtosis in real data samples
	},
	doi          = {
		10.1027/1614-2241/a000057
	},
	number       = {
		2
	},
	pages        = {
		78--84
	},
	volume       = {
		9
	},
	publisher    = {
		Hogrefe Publishing Group
	},
	abstract     = {
		Parametric statistics are based on the assumption of normality.
		Recent findings suggest that Type I error and power can be adversely affected when data are non-normal.
		This paper aims to assess the distributional shape of real data by examining the values of the third and fourth central moments as a measurement of skewness and kurtosis in small samples.
		The analysis concerned 693 distributions with a sample size ranging from 10 to 30.
		Measures of cognitive ability and of other psychological variables were included.
		The results showed that skewness ranged between -2.49 and 2.33.
		The values of kurtosis ranged between -1.92 and 7.41.
		Considering skewness and kurtosis together the results indicated that only 5.5\% of distributions were close to expected values under normality.
		Although extreme contamination does not seem to be very frequent,
		the findings are consistent with previous research suggesting that normality is not the rule with real data.
	},
}

@Article{
	Lib-Nonnormality-Bono-2017,
	author       = {
		Bono, Roser 
		and 
		Blanca, Mar{\'{\i}}a J. 
		and 
		Arnau, Jaume 
		and 
		G{\'{o}}mez-Benito, 
		Juana
	},
	date         = {
		2017-09
	},
	journaltitle = {
		Frontiers in Psychology
	},
	title        = {
		Non-normal distributions commonly used in health, education, and social sciences: A systematic review
	},
	doi          = {
		10.3389/fpsyg.2017.01602
	},
	volume       = {
		8
	},
	publisher    = {
		Frontiers Media {SA}
	},
	abstract = {
		Statistical analysis is crucial for research and the choice of analytical technique should take into account the specific distribution of data.
		Although the data obtained from health,
		educational,
		and social sciences research are often not normally distributed,
		there are very few studies detailing which distributions are most likely to represent data in these disciplines.
		The aim of this systematic review was to determine the frequency of appearance of the most common non-normal distributions in the health, 
		educational,
		and social sciences.
		The search was carried out in the Web of Science database,
		from which we retrieved the abstracts of papers published between 2010 and 2015.
		The selection was made on the basis of the title and the abstract,
		and was performed independently by two reviewers.
		The inter-rater reliability for article selection was high (Cohen’s kappa = 0.84),
		and agreement regarding the type of distribution reached 96.5\%.
		A total of 262 abstracts were included in the final review.
		The distribution of the response variable was reported in 231 of these abstracts,
		while in the remaining 31 it was merely stated that the distribution was non-normal.
		In terms of their frequency of appearance,
		the most-common non-normal distributions can be ranked in descending order as follows:
		gamma,
		negative binomial,
		multinomial,
		binomial,
		lognormal,
		and exponential.
		In addition to identifying the distributions most commonly used in empirical studies these results will help researchers to decide which distributions should be included in simulation studies examining statistical procedures.
	},
}

@Comment{jabref-meta: databaseType:biblatex;}
% Encoding: US-ASCII

@Manual{
	Lib-R-Manual-2021
	,
	title = {
		{R}: A language and environment for statistical computing
	},
	author = {
		{R Core Team}
	},
	organization = {
		R Foundation for Statistical Computing
	},
	date = {
		2021
	},
	location = {
		Vienna, Austria
	},
	url = {
		https://www.R-project.org/
	},
	annotation = {
		Lib-R-Manual
	}
}

@Manual{
	Lib-R-Manual-2022
	,
	title = {
		{R}: A language and environment for statistical computing
	},
	author = {
		{R Core Team}
	},
	organization = {
		R Foundation for Statistical Computing
	},
	date = {
		2022
	},
	location = {
		Vienna, Austria
	},
	url = {
		https://www.R-project.org/
	},
	annotation = {
		Lib-R-Manual
	}
}

@Comment{jabref-meta: databaseType:biblatex;}
% Encoding: US-ASCII

@Book{
	Lib-R-Packages-MASS-2002
	,
	author    = {
		Venables, W. N. 
		and 
		Ripley, B. D.
	},
	date      = {
		2002
	},
	title     = {
		Modern applied statistics with {S}
	},
	doi       = {
		10.1007/978-0-387-21706-2
	},
	publisher = {
		Springer New York
	},
	annotation = {
		Lib-R-Packages
	},
}

@Article{
	Lib-R-Packages-mice-2011
	,
	author       = {
		Stef van Buuren 
		and 
		Karin Groothuis-Oudshoorn
	},
	date         = {
		2011
	},
	journaltitle = {
		Journal of Statistical Software
	},
	title        = {
		{mice}: Multivariate Imputation by Chained Equations in {R}
	},
	doi          = {
		10.18637/jss.v045.i03
	},
	number       = {
		3
	},
	volume       = {
		45
	},
	publisher    = {
		Foundation for Open Access Statistic
	},
	file = {
		references/10.18637%2Fjss.v045.i03.pdf
	},
	library = {},
	keywords = {
		MICE, 
		multiple imputation, 
		chained equations, 
		fully conditional specification,
		Gibbs sampler, 
		predictor selection, 
		passive imputation, 
		R.
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-R-Packages
	},
	abstract = {
		The R package mice imputes incomplete multivariate data by chained equations. 
		The software mice 1.0 appeared in the year 2000 as an S-PLUS library, and in 2001 as an R package. 
		mice 1.0 introduced predictor selection, passive imputation and automatic pooling. 
		This article documents mice, which extends the functionality of mice 1.0 in several ways. 
		In mice, the analysis of imputed data is made completely general, whereas the range of models under which pooling works is substantially extended. 
		mice adds new functionality for imputing multilevel data, automatic predictor selection, data handling, post-processing imputed values, specialized pooling routines, model selection tools, and diagnostic graphs.
		Imputation of categorical data is improved in order to bypass problems caused by perfect prediction. 
		Special attention is paid to transformations, sum scores, indices and interactions using passive imputation, and to the proper setup of the predictor matrix. 
		mice can be downloaded from the Comprehensive R Archive Network. 
		This article provides a hands-on, stepwise approach to solve applied incomplete data problems.
	},
}

@Manual{
	Lib-R-Packages-bootstrap-2019
	,
	title = {
		{bootstrap}: Functions for the Book ``{An introduction to the bootstrap}''
	},
	author = {
		Tibshirani, Rob
		and
		Leisch, Friedrich
	},
	date = {
		2019
	},
	note = {
		R package version 2019.6
	},
	addendum = {
		(S original and from StatLib and by Rob Tibshirani.
		R port by Friedrich Leisch.)
	},
	url = {
		"https://CRAN.R-project.org/package=bootstrap"
	},
	annotation = {
		Lib-R-Packages
	},
	abstract = {
		Software (bootstrap, cross-validation, jackknife) and data
		for the book ``An Introduction to the Bootstrap''
		by B. Efron and R. Tibshirani, 1993, Chapman and Hall.
		This package is primarily provided for projects already based on it,
		and for support of the book.
		New projects should preferentially use the recommended package ``boot''.
	}
}
  
@Manual{
	Lib-R-Packages-boot-2020
	,
	title = {
		{boot}: Bootstrap {R (S-Plus)} Functions
	},
	author = {
		Canty, Angelo
		and
	Ripley, B. D.},
	date = {2020},
	note = {
		R package version 1.3-25
	},
	url = {
		"https://CRAN.R-project.org/package=boot"
	},
	annotation = {
		Lib-R-Packages
	},
	abstract = {
		Functions and datasets for bootstrapping
		from the book ``Bootstrap Methods and Their Application''
		by A. C. Davison and D. V. Hinkley (1997, CUP),
		originally written by Angelo Canty for \texttt{S}.
	}
}

@Manual{
	Lib-R-Packages-lm.beta-2014
	,
	title  = {
		{lm.beta}: Add standardized regression coefficients to lm-objects
	},
	author = {
		Behrendt, Stefan
	},
	date   = {
		2014
	},
	note = {
		R package version 1.5-1
	},
	url    = {
		"https://CRAN.R-project.org/package=lm.beta"
	},
	annotation = {
		Lib-R-Packages
	},
}

@Manual{
	Lib-R-Packages-jmv-2020
	,
	title = {
		{jmv}: The 'jamovi' Analyses
	},
	author = {
		Selker, Ravi 
		and 
		Love, Jonathon 
		and 
		Dropmann, Damian
	},
	date = {
		2020
	},
	note = {
		R package version 1.2.23
	},
	url = {
		"https://CRAN.R-project.org/package=jmv"
	},
	annotation = {
		Lib-R-Packages
	},
}

@Manual{
	Lib-R-Packages-jasp-2022
	,
	author = {
		{JASP Team}
	},
	title = {
		{JASP (Version 0.16.1)[Computer software]}
	},
	date = {
		2022
	},
	url = {
		"https://jasp-stats.org/"
	},
	annotation = {
		Lib-R-Packages
	},
}

% Rocker

@Article{
	Lib-R-Packages-Boettiger-2017
	,
	author       = {
		Boettiger, Carl 
		and 
		Eddelbuettel, Dirk
	},
	date         = {
		2017
	},
	journaltitle = {
		The R Journal
	},
	title        = {
		An introduction to {Rocker}: Docker containers for {R}
	},
	doi          = {
		10.32614/rj-2017-065
	},
	number       = {
		2
	},
	pages        = {
		527
	},
	volume       = {
		9
	},
	abstract     = {
		We describe the Rocker project, 
		which provides a widely-used suite of Docker images with customized R environments for particular tasks. 
		We discuss how this suite is organized, 
		and how these tools can increase portability, 
		scaling, 
		reproducibility, 
		and convenience of R users and developers.
	},
	publisher    = {
		The R Foundation
	},
	annotation = {
		Lib-R-Packages
	},
}

@Article{
	Lib-R-Packages-Nuest-2020
	,
	author = {
		Nüst, Daniel
		and
		Eddelbuettel, Dirk
		and
		Bennett, Dom
		and
		Cannoodt, Robrecht 
		and 
		Clark, Dav 
		and 
		Daróczi, Gergely 
		and
		Edmondson, Mark 
		and 
		Fay, Colin 
		and 
		Hughes, Ellis 
		and 
		Kjeldgaard, Lars 
		and 
		Lopp, Sean 
		and 
		Marwick, Ben 
		and 
		Nolis, Heather
		and 
		Nolis, Jacqueline 
		and 
		Ooi, Hong 
		and 
		Ram, Karthik 
		and 
		Ross, Noam 
		and 
		Shepherd, Lori 
		and 
		Sólymos, Péter 
		and 
										
		Swetnam, Tyson Lee
		and 
		Turaga, Nitesh 
		and 
		Van Petegem, Charlotte
		and
		Williams, Jason
		and
		Willis, Craig
		and
		Xiao, Nan
	},
	date         = {
		2020
	},
	journaltitle = {
		The R Journal
	},
	title        = {
		The {Rockerverse}: Packages and applications for containerisation with {R}
	},
	doi          = {
		10.32614/rj-2020-007
	},
	number       = {
		1
	},
	pages        = {
		437
	},
	volume       = {
		12
	},
	abstract     = {
		The Rocker Project provides widely used Docker images for R across different application scenarios. 
		This article surveys downstream projects that build upon the Rocker Project images and presents the current state of R packages for managing Docker images and controlling containers. 
		These use cases cover diverse topics such as package development, 
		reproducible research, 
		collaborative work, 
		cloud-based data processing, 
		and production deployment of services. 
		The variety of applications demonstrates the power of the Rocker Project specifically and containerisation in general. 
		Across the diverse ways to use containers, we identified common themes: 
		reproducible environments, 
		scalability and efficiency, 
		and portability across clouds. 
		We conclude that the current growth and diversification of use cases is likely to continue its positive impact, 
		but see the need for consolidating the Rockerverse ecosystem of packages, 
		developing common practices for applications, and exploring alternative containerisation software.
	},
	publisher    = {
		The R Foundation
	},
	annotation = {
		Lib-R-Packages
	},
}

@Manual{
	Lib-R-Packages-shiny-2020
	,
	author = {
		Chang, Winston 
		and 
		Cheng, Joe 
		and 
		Allaire, J. J. 
		and 
		Xie, Yihui 
		and 
		McPherson, Jonathan
	},
	title = {
		{shiny}: Web application framework for {R}
	}
	,
	year = {
		2020
	},
	note = {
		R package version 1.5.0
	},
	url = {
		"https://CRAN.R-project.org/package=shiny"
	},
	publisher    = {
		The R Foundation
	},
	annotation = {
		Lib-R-Packages
	},
}

@Manual{
	Lib-R-Packages-fungible-2022
	,
	author = {
		Waller, Niels G.
	},
	title = {
		{fungible}: Psychometric functions from the {Waller Lab}
	}
	,
	year = {
		2022
	},
	note = {
		R package version 2.2.1
	},
	url = {
		"https://CRAN.R-project.org/package=fungible"
	},
	publisher    = {
		The R Foundation
	},
	annotation = {
		Lib-R-Packages
	},
}
  
@Comment{jabref-meta: databaseType:biblatex;}
% Encoding: US-ASCII

@Article{
Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-White-1980,
  author       = {White, Halbert},
  date         = {1980-05},
  journaltitle = {Econometrica},
  title        = {A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity},
  doi          = {10.2307/1912934},
  number       = {4},
  pages        = {817},
  volume       = {48},
  publisher    = {{JSTOR}},
  abstract = {This paper presents a parameter covariance matrix estimator which is consistent even when the disturbances of a linear regression model are heteroskedastic. This estimator does not depend on a formal model of the structure of the heteroskedasticity. By comparing the elements of the new estimator to those of the usual covariance estimator, one obtains a direct test for heteroskedasticity, since in the absence of heteroskedasticity, the two estimators will be approximately equal, but will generally diverge otherwise. The test has an appealing least squares interpretation.}
}

@Article{
  Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-Chesher-1987,
  author       = {Chesher, Andrew and Jewitt, Ian},
  date         = {1987-09},
  journaltitle = {Econometrica},
  title        = {The bias of a heteroskedasticity consistent covariance matrix estimator},
  doi          = {10.2307/1911269},
  number       = {5},
  pages        = {1217},
  volume       = {55},
  publisher    = {{JSTOR}},
}

@Article{
Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-Andrews-1991,
  author       = {Andrews, Donald W. K.},
  date         = {1991-05},
  journaltitle = {Econometrica},
  title        = {Heteroskedasticity and autocorrelation consistent covariance matrix estimation},
  doi          = {10.2307/2938229},
  number       = {3},
  pages        = {817},
  volume       = {59},
  publisher    = {{JSTOR}},
}

@Article{
Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-Andrews-1992,
  author       = {Andrews, Donald W. K. and Monahan, J. Christopher},
  date         = {1992-07},
  journaltitle = {Econometrica},
  title        = {An improved heteroskedasticity and autocorrelation consistent covariance matrix estimator},
  doi          = {10.2307/2951574},
  number       = {4},
  pages        = {953},
  volume       = {60},
  publisher    = {{JSTOR}},
}

@Article{
Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-Kauermann-2001,
  author       = {Kauermann, G\"{o}ran and Carroll, Raymond J.},
  date         = {2001-12},
  journaltitle = {Journal of the American Statistical Association},
  title        = {A note on the efficiency of sandwich covariance matrix estimation},
  doi          = {10.1198/016214501753382309},
  number       = {456},
  pages        = {1387--1396},
  volume       = {96},
  abstract     = {The sandwich estimator, also known as robust covariance matrix estimator, heteroscedasticity-consistent covariance matrix estimate, or empirical covariance matrix estimator, has achieved increasing use in the econometric literature as well as with the growing popularity of generalized estimating equations. Its virtue is that it provides consistent estimates of the covariance matrix for parameter estimates even when the fitted parametric model fails to hold or is not even specified. Surprisingly though, there has been little discussion of properties of the sandwich method other than consistency. We investigate the sandwich estimator in quasi-likelihood models asymptotically, and in the linear case analytically. We show that under certain circumstances when the quasi-likelihood model is correct, the sandwich estimate is often far more variable than the usual parametric variance estimate. The increased variance is a fixed feature of the method and the price that one pays to obtain consistency even when the parametric model fails or when there is heteroscedasticity. We show that the additional variability directly affects the coverage probability of confidence intervals constructed from sandwich variance estimates. In fact, the use of sandwich variance estimates combined with t-distribution quantiles gives confidence intervals with coverage probability falling below the nominal value. We propose an adjustment to compensate for this fact.},
  publisher    = {Informa {UK} Limited},
}


@Article{
Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-Cribari-Neto-2004,
  author       = {Cribari-Neto, Francisco},
  date         = {2004-03},
  journaltitle = {Computational Statistics {\&} Data Analysis},
  title        = {Asymptotic inference under heteroskedasticity of unknown form},
  doi          = {10.1016/s0167-9473(02)00366-3},
  number       = {2},
  pages        = {215--233},
  volume       = {45},
  publisher    = {Elsevier {BV}},
  abstract = {We focus on the finite-sample behavior of heteroskedasticity-consistent covariance matrix estimators and associated quasi-t tests. The estimator most commonly used is that proposed by Halbert White. Its finite-sample behavior under both homoskedasticity and heteroskedasticity is analyzed using Monte Carlo methods. We also consider two other consistent estimators, namely: the HC3 estimator, which is an approximation to the jackknife estimator, and the weighted bootstrap estimator. Additionally, we evaluate the finite-sample behavior of two bootstrap quasi-t tests: the test based on a single bootstrapping scheme and the test based on a double, nested bootstrapping scheme. The latter is very computer-intensive, but proves to work well in small samples. Finally, we propose a new estimator, which we call HC4; it is tailored to take into account the effect of leverage points in the design matrix on associated quasi-t tests.}
}

@Article{
Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-Cribari-Neto-2010,
  author       = {Cribari-Neto, Francisco and da Silva, Wilton Bernardino},
  date         = {2010-11},
  journaltitle = {{AStA} Advances in Statistical Analysis},
  title        = {A new heteroskedasticity-consistent covariance matrix estimator for the linear regression model},
  doi          = {10.1007/s10182-010-0141-2},
  number       = {2},
  pages        = {129--146},
  volume       = {95},
  publisher    = {Springer Science and Business Media {LLC}},
  abstract = {The assumption that all random errors in the linear regression model share the same variance (homoskedasticity) is often violated in practice. The ordinary least squares estimator of the vector of regression parameters remains unbiased, consistent and asymptotically normal under unequal error variances. Many practitioners then choose to base their inferences on such an estimator. The usual practice is to couple it with an asymptotically valid estimation of its covariance matrix, and then carry out hypothesis tests that are valid under heteroskedasticity of unknown form. We use numerical integration methods to compute the exact null distributions of some quasi-t test statistics, and propose a new covariance matrix estimator. The numerical results favor testing inference based on the estimator we propose.}
}

@Article{
Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-Cribari-Neto-2007,
  author       = {Cribari-Neto, Francisco and Souza, Tatiene C. and Vasconcellos, Klaus L. P.},
  date         = {2007-08},
  journaltitle = {Communications in Statistics - Theory and Methods},
  title        = {Inference under heteroskedasticity and leveraged data},
  doi          = {10.1080/03610920601126589},
  number       = {10},
  pages        = {1877--1888},
  volume       = {36},
  publisher    = {Informa {UK} Limited},
  abstract = {
  We evaluate the finite-sample behavior of different heteros-ke-das-ticity-consistent covariance matrix estimators, under both constant and unequal error variances. We consider the estimator proposed by Halbert White (HC0), and also its variants known as HC2, HC3, and HC4; the latter was recently proposed by Cribari-Neto (2004). We propose a new covariance matrix estimator: HC5. It is the first consistent estimator to explicitly take into account the effect that the maximal leverage has on the associated inference. Our numerical results show that quasi-t inference based on HC5 is typically more reliable than inference based on other covariance matrix estimators.
  }
}

@Article{
Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-Dudgeon-2017,
  author       = {Dudgeon, Paul},
  date         = {2017-03},
  journaltitle = {Psychometrika},
  title        = {Some improvements in confidence intervals for standardized regression coefficients},
  doi          = {10.1007/s11336-017-9563-z},
  number       = {4},
  pages        = {928--951},
  volume       = {82},
  publisher    = {Springer Science and Business Media {LLC}},
}

@Article{
Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-Hayes-2007,
  author       = {Hayes, Andrew F. and Cai, Li},
  date         = {2007-11},
  journaltitle = {Behavior Research Methods},
  title        = {Using heteroskedasticity-consistent standard error estimators in {OLS} regression: An introduction and software implementation},
  doi          = {10.3758/bf03192961},
  number       = {4},
  pages        = {709--722},
  volume       = {39},
  publisher    = {Springer Science and Business Media {LLC}},
}

@Article{
Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-Long-2000,
  author       = {Long, J. Scott and Ervin, Laurie H.},
  date         = {2000-08},
  journaltitle = {The American Statistician},
  title        = {Using heteroscedasticity consistent standard errors in the linear regression model},
  doi          = {10.1080/00031305.2000.10474549},
  number       = {3},
  pages        = {217--224},
  volume       = {54},
  publisher    = {Informa {UK} Limited},
}

@Article{
Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-MacKinnon-1985,
  author       = {MacKinnon, James G. and White, Halbert},
  date         = {1985-09},
  journaltitle = {Journal of Econometrics},
  title        = {Some heteroskedasticity-consistent covariance matrix estimators with improved finite sample properties},
  doi          = {10.1016/0304-4076(85)90158-7},
  number       = {3},
  pages        = {305--325},
  volume       = {29},
  publisher    = {Elsevier {BV}},
}



@Article{
Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-Zeileis-2004,
  author       = {Zeileis, Achim},
  date         = {2004},
  journaltitle = {Journal of Statistical Software},
  title        = {Econometric computing with {HC} and {HAC} covariance matrix estimators},
  doi          = {10.18637/jss.v011.i10},
  number       = {10},
  volume       = {11},
  publisher    = {Foundation for Open Access Statistic},
}

@Article{
Lib-Regression-Heteroskedasticity-Consistent-Standard-Errors-Hinkley-1977,
  author       = {Hinkley, David V.},
  date         = {1977-08},
  journaltitle = {Technometrics},
  title        = {Jackknifing in unbalanced situations},
  doi          = {10.1080/00401706.1977.10489550},
  number       = {3},
  pages        = {285--292},
  volume       = {19},
  publisher    = {Informa {UK} Limited},
}


@Comment{jabref-meta: databaseType:biblatex;}
% Encoding: US-ASCII

@Article{
	Lib-Regression-Standardized-Coefficients-Delta-Yuan-2011
	,
	author = {
		Yuan, Ke-Hai 
		and 
		Chan, Wai
	},
	date = {
		2011-08
	},
	journaltitle = {
		Psychometrika
	},
	title = {
		Biases and standard errors of standardized regression coefficients
	},
	doi = {
		10.1007/s11336-011-9224-6
	},
	number = {
		4
	},
	pages = {
		670--690
	},
	volume = {
		76
	},
	publisher = {
		Springer Science and Business Media {LLC}
	},
	file = {
		references/10.1007%2FS11336-011-9224-6.pdf
	},
	library = {},
	keywords = {
		asymptotics,
		bias,
		consistency,
		Monte Carlo
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Regression-Standardized-Coefficients-Delta
	},
	abstract = {
		The paper obtains consistent standard errors (SE)
		and biases of order $O(1/n)$
		for the sample standardized regression coefficients
		with both random and given predictors.
		Analytical results indicate that the formulas for SEs
		given in popular text books are consistent
		only when the population value
		of the regression coefficient is zero.
		The sample standardized regression coefficients
		are also biased in general,
		although it should not be a concern in practice
		when the sample size is not too small.
		Monte Carlo results imply that,
		for both standardized and unstandardized
		sample regression coefficients,
		SE estimates based on asymptotics tend to under-predict
		the empirical ones at smaller sample sizes.
	},
}

@Article{
	Lib-Regression-Standardized-Coefficients-Delta-Jones-2013a
	,
	author = {
		Jones, Jeff A. 
		and 
		Waller, Niels G.
	},
	date = {
		2013
	},
	journaltitle = {
		Psychological Methods
	},
	title = {
		Computing confidence intervals for standardized regression coefficients.
	},
	doi = {
		10.1037/a0033269
	},
	number = {
		4
	},
	pages = {
		435--453
	},
	volume = {
		18
	},
	publisher = {
		American Psychological Association ({APA})
	},
	file = {
		references/10.1037%2Fa0033269.pdf
	},
	library = {},
	keywords = {
		standard errors, 
		multiple regression, 
		delta method, 
		confidence intervals
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Regression-Standardized-Coefficients-Delta
	},
	abstract = {
		With fixed predictors,
		the standard method
		(Cohen, Cohen, West, \& Aiken, 2003, p. 86;
		Harris, 2001, p. 80;
		Hays, 1994, p. 709)
		for computing confidence intervals (CIs)
		for standardized regression coefficients
		fails to account for the sampling variability
		of the criterion standard deviation.
		With random predictors,
		this method also fails to account
		for the sampling variability
		of the predictor standard deviations.
		Nevertheless,
		under some conditions the standard method will produce CIs
		with accurate coverage rates.
		To delineate these conditions,
		we used a Monte Carlo simulation
		to compute empirical CI coverage rates
		in samples drawn from 36 populations
		with a wide range of data characteristics.
		We also computed the empirical CI coverage rates
		for 4 alternative methods that have been discussed
		in the literature:
		noncentrality interval estimation,
		the delta method,
		the percentile bootstrap,
		and the bias-corrected and accelerated bootstrap.
		Our results showed that
		for many data-parameter configurations--for example,
		sample size,
		predictor correlations,
		coefficient of determination (
		$
		R^2
		$
		),
		orientation of $\beta$
		with respect to the eigenvectors
		of the predictor correlation matrix,
		$
		R_X
		$--the standard method produced coverage rates
		that were close to their expected values.
		However,
		when population $R^2$ was large
		and when $\beta$ approached the last eigenvector of
		$
		R_X
		$,
		then the standard method coverage rates
		were frequently below the nominal rate
		(sometimes by a considerable amount).
		In these conditions,
		the delta method and the 2 bootstrap procedures
		were consistently accurate.
		Results using noncentrality interval estimation
		were inconsistent.
		In light of these findings,
		we recommend that researchers use the delta method
		to evaluate the sampling variability
		of standardized regression coefficients.
	},
}

@Report{
	Lib-Regression-Standardized-Coefficients-Delta-Jones-2013b
	,
	author = {
		Jones, Jeff A.
		and
		Waller, Niels G.
	},
	date = {
		2013-05-25
	},
	institution = {
		University of Minnesota-Twin Cities
	},
	title = {
		The normal-theory and asymptotic distribution-free ({ADF})
		covariance matrix of standardized regression coefficients:
		Theoretical extensions and finite sample behavior
	},
	type = {
		techreport
	},
	url = {
		http://users.cla.umn.edu/~nwaller/downloads/techreports/TR052913.pdf
	},
	urldate = {
		2021-10-18
	},
	file = {
		references/TR052913.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Regression-Standardized-Coefficients-Delta
	},
	abstract = {
		Yuan and Chan (2011)
		recently showed how to compute the covariance matrix
		of standardized regression coefficients from covariances.
		In this paper,
		we describe a new method
		for computing this covariance matrix from correlations.
		We then show that Yuan and Chan's original equations
		can also be used when only correlational data are available.
		Next, we describe an asymptotic distribution-free
		(ADF; Browne, 1984)
		method for computing the covariance matrix
		of standardized regression coefficients.
		We show that theADF method works well with non-normal data
		in moderate-to-large samples using both simulated
		and real-data examples.
		Finally,
		we provide R code (R Development Core Team, 2012)
		in an Appendix to make these methods accessible
		to applied researchers.
	},
}

@Article{
	Lib-Regression-Standardized-Coefficients-Delta-Jones-2015
	,
	author = {
		Jones, Jeff A. 
		and 
		Waller, Niels G.
	},
	date = {
		2015
	},
	journaltitle = {
		Psychometrika
	},
	title = {
		The normal-theory and asymptotic distribution-free ({ADF})
		covariance matrix of standardized regression coefficients:
		Theoretical extensions and finite sample behavior
	},
	doi = {
		10.1007/s11336-013-9380-y
	},
	number = {
		2
	},
	pages = {
		365--378
	},
	volume = {
		80
	},
	publisher = {
		Springer Science and Business Media {LLC}
	},
	file = {
		references/10.1007%2Fs11336-013-9380-y.pdf
	},
	library = {},
	keywords = {
		standardized regression coefficients, 
		multiple regression, 
		ADF, 
		confidence intervals
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Regression-Standardized-Coefficients-Delta
	},
	abstract = {
		Yuan and Chan (Psychometrika, 76, 670–690, 2011)
		recently showed how to compute the covariance matrix
		of standardized regression coefficients from covariances.
		In this paper,
		we describe a method
		for computing this covariance matrix from correlations.
		Next,
		we describe an asymptotic distribution-free
		(ADF;
		Browne in British Journal of Mathematical
		and Statistical Psychology, 37, 62–83, 1984)
		method for computing the covariance matrix
		of standardized regression coefficients.
		We show that the ADF method works well with nonnormal data
		in moderate-to-large samples
		using both simulated and real-data examples.
		\texttt{R} code (R Development Core Team, 2012)
		is available from the authors
		or through the Psychometrika online repository
		for supplementary materials.
	},
}

@Comment{jabref-meta: databaseType:biblatex;}
% Encoding: US-ASCII

@Article{
	Lib-Regression-Standardized-Coefficients-HC-Dudgeon-2017
	,
	author = {
		Dudgeon, Paul
	},
	date = {
		2017-03
	},
	journaltitle = {
		Psychometrika
	},
	title = {
		Some improvements in confidence intervals for standardized regression coefficients
	},
	doi = {
		10.1007/s11336-017-9563-z
	},
	number = {
		4
	},
	pages = {
		928--951
	},
	volume = {
		82
	},
	publisher = {
		Springer Science and Business Media {LLC}
	},
	file = {
		references/10.1007%2Fs11336-017-9563-z.pdf
	},
	library = {},
	keywords = {
		standardized regression coefficients,
		robust confidence intervals,
		non-normality
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Regression-Standardized-Coefficients-HC
	},
	abstract = {
		Yuan and Chan (Psychometrika 76:670–690, 2011. doi:10.1007/S11336-011-9224-6) derived consistent confidence intervals for standardized regression coefficients under fixed and random score assumptions.
		Jones and Waller (Psychometrika 80:365–378, 2015. doi:10.1007/S11336-013-9380-Y) extended these developments to circumstances where data are non-normal by examining confidence intervals based on Browne's (Br J Math Stat Psychol 37:62–83, 1984. doi:10.1111/j.2044-8317.1984.tb00789.x) asymptotic distribution-free (ADF) theory.
		Seven different heteroscedastic-consistent (HC) estimators were investigated in the current study as potentially better solutions for constructing confidence intervals on standardized regression coefficients under non-normality.
		Normal theory, ADF, and HC estimators were evaluated in a Monte Carlo simulation.
		Findings confirmed the superiority of the HC3 (MacKinnon and White, J Econ 35:305–325, 1985. doi:10.1016/0304-4076(85)90158-7) and HC5 (Cribari-Neto and Da Silva, Adv Stat Anal 95:129–146, 2011. doi:10.1007/s10182-010-0141-2) interval estimators over Jones and Waller's ADF estimator under all conditions investigated,
		as well as over the normal theory method.
		The HC5 estimator was more robust in a restricted set of conditions over the HC3 estimator.
		Some possible extensions of HC estimators to other effect size measures are considered for future developments.
	},
}

@Comment{jabref-meta: databaseType:biblatex;}
% Encoding: US-ASCII

@Article{
	Lib-Regression-Standardized-Coefficients-SEM-Cheung-2009a,
	author = {
		Cheung, Mike W.-L.
	},
	date = {2009-05},
	journaltitle = {Behavior Research Methods},
	title = {Comparison of methods for constructing confidence intervals of standardized indirect effects},
	doi = {10.3758/brm.41.2.425},
	number = {2},
	pages = {425--438},
	volume = {41},
	publisher = {Springer Science and Business Media {LLC}},
	abstract = {
		Mediation models are often used as a means to explain the psychological mechanisms between an independent and a dependent variable in the behavioral and social sciences. A major limitation of the unstandardized indirect effect calculated from raw scores is that it cannot be interpreted as an effect-size measure. In contrast, the standardized indirect effect calculated from standardized scores can be a good candidate as a measure of effect size because it is scale invariant. In the present article, 11 methods for constructing the confidence intervals (CIs) of the standardized indirect effects were evaluated via a computer simulation. These included six Wald CIs, three bootstrap CIs, one likelihood-based CI, and the PRODCLIN CI. The results consistently showed that the percentile bootstrap, the bias-corrected bootstrap, and the likelihood-based approaches had the best coverage probability. Mplus, LISREL, and Mx syntax were included to facilitate the use of these preferred methods in applied settings. Future issues on the use of the standardized indirect effects are discussed.
	},
}

@Article{
	Lib-Regression-Standardized-Coefficients-SEM-Kwan-2011,
	author = {
		Kwan, Joyce L. Y. 
		and 
		Chan, Wai
	},
	date = {2011-04},
	journaltitle = {Behavior Research Methods},
	title = {Comparing standardized coefficients in structural equation modeling: A model reparameterization approach},
	doi = {10.3758/s13428-011-0088-6},
	number = {3},
	pages = {730--745},
	volume = {43},
	publisher = {Springer Science and Business Media {LLC}},
	abstract = {
		We propose a two-stage method for comparing standardized coefficients in structural equation modeling (SEM). At stage 1, we transform the original model of interest into the standardized model by model reparameterization, so that the model parameters appearing in the standardized model are equivalent to the standardized parameters of the original model. At stage 2, we impose appropriate linear equality constraints on the standardized model and use a likelihood ratio test to make statistical inferences about the equality of standardized coefficients. Unlike other existing methods for comparing standardized coefficients, the proposed method does not require specific modeling features (e.g., specification of nonlinear constraints), which are available only in certain SEM software programs. Moreover, this method allows researchers to compare two or more standardized coefficients simultaneously in a standard and convenient way. Three real examples are given to illustrate the proposed method, using EQS, a popular SEM software program. Results show that the proposed method performs satisfactorily for testing the equality of standardized coefficients.
	},
}

@Comment{jabref-meta: databaseType:biblatex;}
% Encoding: US-ASCII

@Article{
	Lib-Structural-Equation-Modeling-ADF-Browne-1984
	,
	author = {
		Browne, Michael W.
	},
	date = {
		1984-05
	},
	journaltitle = {
		British Journal of Mathematical and Statistical Psychology
	},
	title = {
		Asymptotically distribution-free methods for the analysis of covariance structures
	},
	doi = {
		10.1111/j.2044-8317.1984.tb00789.x
	},
	number = {
		1
	},
	pages = {
		62--83
	},
	volume = {
		37
	},
	publisher = {
		Wiley
	},
	abstract = {
		Methods for obtaining tests of fit of structural models
		for covariance matrices and estimator standard error
		which are asymptotically distribution free are derived.
		Modifications to standard normal theory tests
		and standard errors
		which make them applicable to the wider class of elliptical distributions
		are provided.
		A random sampling experiment
		to investigate some of the proposed methods is described.
	},
}

@Article{
	Lib-Structural-Equation-Modeling-ADF-Koning-1992
	,
	author = {
		Koning, Ruud H. 
		and 
		Neudecker, Heinz 
		and 
		Wansbeek, Tom
	},
	date = {
		1992-01
	},
	journaltitle = {
		Linear Algebra and its Applications
	},
	title = {
		Unbiased estimation of fourth-order matrix moments
	},
	doi = {
		10.1016/0024-3795(92)90445-g
	},
	pages = {
		163--174
	},
	volume = {
		160
	},
	publisher = {
		Elsevier {BV}
	},
	abstract = {
		We formulate Browne's (1984) unbiased estimator
		for the elements of the matrix of fourth-order moments in terms of matrices.
		We show that this matrix is indeed an unbiased estimator, 
		without using the theory of cumulants and $k$-statistics.
	},
}

@Article{
	Lib-Structural-Equation-Modeling-ADF-Yung-1994
	,
	author = {
		Yung, Yiu-Fai 
		and 
		Bentler, Peter M.
	},
	date = {
		1994-05
	},
	journaltitle = {
		British Journal of Mathematical and Statistical Psychology
	},
	title = {
		Bootstrap-corrected {ADF} test statistics in covariance structure analysis
	},
	doi = {
		10.1111/j.2044-8317.1994.tb01025.x
	},
	number = {
		1
	},
	pages = {
		63--84
	},
	volume = {
		47
	},
	publisher = {
		Wiley
	},
	abstract = {
		The asymptotically distribution-free (ADF) test statistic 
		for covariance structure analysis (CSA) 
		has been reported to perform very poorly in simulation studies, 
		i.e. it leads to inaccurate decisions 
		regarding the adequacy of models of psychological processes. 
		It is shown in the present study 
		that the poor performance of the ADF test statistic 
		is due to inadequate estimation of the weight matrix
		($W = \boldsymbol{\Gamma}^{-1}$), 
		which is a critical quantity in the ADF theory. 
		Bootstrap procedures based on Hall's bias reduction perspective 
		are proposed to correct the ADF test statistic. 
		It is shown that the bootstrap correction 
		of additive bias on the ADF test statistic 
		yields the desired tail behaviour 
		as the sample size reaches 500 
		for a 15-variable-3-factor confirmatory factor-analytic model, 
		even if the distribution of the observed variables 
		is not multivariate normal 
		and the latent factors are dependent. 
		These results help to revive the ADF theory in CSA.
	},
}
 
@Article{
	Lib-Structural-Equation-Modeling-ADF-Chan-1995
	,
	author = {
		Chan, Wai 
		and 
		Yung, Yiu-Fai 
		and 
		Bentler, Peter M.
	},
	date = {
		1995-10
	},
	journaltitle = {
		Multivariate Behavioral Research
	},
	title = {
		A note on using and unbiased weight matrix in the {ADF} test statistic
	},
	doi = {
		10.1207/s15327906mbr3004_1
	},
	number = {
		4
	},
	pages = {
		453--459
	},
	volume = {
		30
	},
	publisher = {
		Informa {UK} Limited
	},
	abstract = {
		In covariance structure analysis, 
		the asymptotically distribution-free (ADF) method 
		fails to work satisfactorily unless the sample is extremely large. 
		Simulation studies report that the ADF test statistics observed 
		are usually too large 
		and correct models are then over-rejected. 
		It is known that the accuracy of the ADF test statistic 
		depends on the estimation of the weight matrix. 
		In existing literature and computer software, 
		a biased estimator $\tilde{W}$
		is used as an estimate of the unknown weight matrix.
		In this article,
		we suggest that $\hat{W}$,
		an unbiased estimate of the weight matrix,
		may eliminate the small or intermediate sample size bias
		of the ADF test statistic.
		Results show that the test statistics based 
		on $\tilde{W}$ and $\hat{W}$ are highly similar.
		The poor performance of the ADF method 
		was not caused by the use of a biased weight matrix 
		in the model studied in this article.
	},
}
 
@Article{
	Lib-Structural-Equation-Modeling-ADF-Hernandez-1997
	,
	author = {
		Hern{\'{a}}ndez, Juan A. 
		and 
		Ram{\'{i}}rez, Gustavo 
		and 
		S{\'{a}}nchez, Alfonso
	},
	date = {
		1997-06
	},
	journaltitle = {
		Behavior Research Methods, Instruments, {\&} Computers
	},
	title = {
		A high-level language program to obtain the bootstrap corrected {ADF} test statistic
	},
	doi = {
		10.3758/bf03204830
	},
	number = {
		2
	},
	pages = {
		296--301
	},
	volume = {
		29
	},
	publisher = {
		Springer Science and Business Media {LLC}
	},
	abstract = {
		A high-level language program 
		to obtain the bootstrap-corrected asymptotic distribution-free (ADF) test statistic
		proposed by Yung and Bentler (1994) is reviewed. 
		The program uses the Gauss-Newton algorithm, 
		first 
		to obtain the ADF test statistic 
		from the raw data, 
		and second, 
		to achieve the corrected test statistic 
		from 500 independent bootstrap samples. 
		A generator of nonnormal random samples 
		was also implemented, 
		according to the algorithms of Fleishman (1978) 
		and Vale and Maurelli (1983), 
		which permits the realization of Monte Carlo simulations. 
		Furthermore, 
		the open nature of the program facilitates 
		the inclusion of new procedures as well as the possibility 
		of increased control of the procedures, variables, and equations.
	},
}
 
@Comment{jabref-meta: databaseType:biblatex;}
% Encoding: US-ASCII

@Book{
	Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification-Fuller-1987
	,
	author    = {
		Fuller, Wayne A.
	},
	date      = {
		1987-06
	},
	title     = {
		Measurement error models
	},
	doi       = {
		10.1002/9780470316665
	},
	editor    = {
		Fuller, Wayne A.
	},
	publisher = {
		John Wiley {\&} Sons, Inc.
	},
	file = {
		references/9780470316665.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification
	},
}

@InBook{
	Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification-Satorra-1994
	,
	author    = {
		Satorra, A.
		and
		Bentler, P. M.
	},
	booktitle = {
		Latent variables analysis: Applications for developmental research
	},
	date      = {
		1994
	},
	title     = {
		Corrections to test statistics and standard errors in covariance structure analysis
	},
	editor    = {
		von Eye A.
		and
		Clogg, C. C.
	},
	pages     = {
		399--419
	},
	file = {},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification
	},
	abstract  = {
		A. Satorra and P. Bentler . . . developed an approach to the asymptotic behavior of covariance structure statistics that rather naturally yields corrections to the goodness-of-fit statistic of the scaling and Satterthwaite types / present these results and . . . illustrate how they improve upon the uncorrected statistics that are now implemented in the field of covariance structure analysis / [show] that the proposed corrections not only encompass the ones advocated by A. Shapiro and M. Browne (1987) in case of elliptical data but do not suffer from the drawback of Browne-Shapiro's corrections of lack of robustness against deviations from the assumption of an elliptical distribution / provides a theory for correcting the standard covariance matrix of the vector of parameter estimates},
}

@Article{
	Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification-Hoogland-1998
	,
	author       = {
		Hoogland, Jeffrey J.
		and
		Boosma, Anne
	},
	date         = {
		1998-02
	},
	journaltitle = {
		Sociological Methods {\&} Research
	},
	title        = {
		Robustness studies in covariance structure modeling
	},
	doi          = {
		10.1177/0049124198026003003
	},
	number       = {
		3
	},
	pages        = {
		329--367
	},
	volume       = {
		26
	},
	publisher    = {{SAGE} Publications},
	file = {
		references/10.1177%2F0049124198026003003.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification
	},
	abstract     = {
		In covariance structure modeling,
		several estimation methods are available.
		The robustness of an estimator against specific violations of assumptions can be determined empirically by means of a Monte Carlo study.
		Many such studies in covariance structure analysis have been published,
		but the conclusions frequently seem to contradict each other.
		An overview of robustness studies in covariance structure analysis is given,
		and an attempt is made to generalize findings.
		Robustness studies are described and distinguished from each other systematically by means of certain characteristics.
		These characteristics serve as explanatory variables in a meta-analysis concerning the behavior of parameter estimators,
		standard error estimators,
		and goodness-of-fit statistics when the model is correctly specified.
	},
}

@Article{
	Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification-Satorra-2001
	,
	author       = {
		Satorra, Albert 
		and
		Bentler, Peter M.
	},
	date         = {
		2001-12
	},
	journaltitle = {
		Psychometrika
	},
	title        = {
		A scaled difference chi-square test statistic for moment structure analysis
	},
	doi          = {
		10.1007/bf02296192
	},
	number       = {
		4
	},
	pages        = {
		507--514
	},
	volume       = {
		66
	},
	publisher    = {
		Springer Science and Business Media {LLC}
	},
	file = {
		references/10.1007%2Fbf02296192.pdf
	},
	library = {},
	keywords = {
		moment-structures,
		goodness-of-fit test,
		chi-square difference test statistic,
		chi-square distribution,
		nonnormality
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification
	},
	abstract     = {
		A family of scaling corrections aimed to improve the chi-square approximation of goodness-of-fit test statistics in small samples,
		large models,
		and nonnormal data was proposed in Satorra and Bentler (1994).
		For structural equations models,
		Satorra-Bentler's (SB) scaling corrections are available in standard computer software.
		Often,
		however,
		the interest is not on the overall fit of a model,
		but on a test of the restrictions that a null model say $M_{0}$ implies on a less restricted one $M_{1}$.
		If $T_{0}$ and $T_{1}$ denote the goodness-of-fit test statistics associated to $M_{0}$ and $M_{1}$,
		respectively,
		then typically the difference $T_{d} = T_{0} - T_{1}$ is used as a chi-square test statistic with degrees of freedom equal to the difference on the number of independent parameters estimated under the models $M_{0}$ and $M_{1}$.
		As in the case of the goodness-of-fit test,
		it is of interest to scale the statistic $T_{d}$ in order to improve its chi-square approximation in realistic,
		that is,
		nonasymptotic and nonormal,
		applications.
		In a recent paper,
		Satorra (2000) shows that the difference between two SB scaled test statistics for overall model fit does not yield the correct SB scaled difference test statistic.
		Satorra developed an expression that permits scaling the difference test statistic,
		but his formula has some practical limitations,
		since it requires heavy computations that are not available in standard computer software.
		The purpose of the present paper is to provide an easy way to compute the scaled difference chi-square statistic from the scaled goodness-of-fit test statistics of models $M_{0}$ and $M_{1}$.
		A Monte Carlo study is provided to illustrate the performance of the competing statistics.
	},
}

@Article{
	Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification-Savalei-2014
	,
	author       = {
		Savalei, Victoria
	},
	date         = {
		2014-01
	},
	journaltitle = {
		Structural Equation Modeling: A Multidisciplinary Journal
	},
	title        = {
		Understanding robust corrections in structural equation modeling
	},
	doi          = {
		10.1080/10705511.2013.824793
	},
	number       = {
		1
	},
	pages        = {
		149--160
	},
	volume       = {
		21
	},
	publisher    = {
		Informa {UK} Limited
	},
	file = {
		references/10.1080%2F10705511.2013.824793.pdf
	},
	library = {},
	keywords = {
		nonnormal data,
		robust standard errors,
		Satorra-Bentler scaled chi-square
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification
	},
	abstract     = {
		Robust corrections to standard errors and test statistics have wide applications in structural equation modeling (SEM). 
		The original SEM development, due to Satorra and Bentler (1988, 1994), was to account for the effect of nonnormality. 
		Muth\'{e}n (1993) proposed corrections to accompany certain categorical data estimators, such as cat-LS or cat-DWLS.
		Other applications of robust corrections exist.
		Despite the diversity of applications, all robust corrections are constructed using the same underlying rationale:
		They correct for inefficiency of the chosen estimator.
		The goal of this article is to make the formulas behind all types of robust corrections more intuitive.
		This is accomplished by building an analogy with similar equations in linear regression and then by reformulating the SEM model as a nonlinear regression model.
	},
}

@Article{
	Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification-Savalei-2021
	,
	author       = {
		Savalei, Victoria 
		and 
		Rosseel, Yves
	},
	date         = {
		2021-10
	},
	journaltitle = {
		Structural Equation Modeling: A Multidisciplinary Journal
	},
	title        = {
		Computational options for standard errors and test statistics with incomplete normal and nonnormal data in {SEM}
	},
	doi          = {
		10.1080/10705511.2021.1877548
	},
	number       = {
		2
	},
	pages        = {
		163--181
	},
	volume       = {
		29
	},
	publisher    = {
		Informa {UK} Limited
	},
	file = {
		references/10.1080%2F10705511.2021.1877548.pdf
	},
	library = {},
	keywords = {
		incomplete data,
		nonnormal data,
		robust corrections,
		software implementation
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification
	},
	abstract     = {
		This article provides an overview of different computational options for inference following normal theory maximum likelihood (ML) estimation in structural equation modeling (SEM) with incomplete normal and nonnormal data.
		Complete data are covered as a special case.
		These computational options include whether the information matrix is observed or expected,
		whether the observed information matrix is estimated numerically or using an analytic asymptotic approximation,
		and whether the information matrix and the outer product matrix of the score vector are evaluated at the saturated or at the structured estimates.
		A variety of different standard errors and robust test statistics become possible by varying these options.
		We review the asymptotic properties of these computational variations, and we show how to obtain them using lavaan in R.
		We hope that this article will encourage methodologists to study the impact of the available computational options on the performance of standard errors and test statistics in SEM.
	},
}

@Article{
	Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification-Du-2021
	,
	author       = {
		Du, Han
		and
		Bentler, Peter M.
	},
	date         = {
		2021-06
	},
	journaltitle = {
		Psychological Methods
	},
	title        = {
		Distributionally weighted least squares in structural equation modeling
	},
	doi          = {
		10.1037/met0000388
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	file = {
		references/10.1037%2Fmet0000388.pdf
	},
	library = {},
	keywords = {
		SEM,
		robust,
		statistics
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Structural-Equation-Modeling-Nonnormality-and-Misspecification
	},
	abstract     = {
		In real data analysis with structural equation modeling,
		data are unlikely to be exactly normally distributed.
		If we ignore the non-normality reality,
		the parameter estimates,
		standard error estimates,
		and model fit statistics from normal theory based methods such as maximum likelihood (ML) and normal theory based generalized least squares estimation (GLS) are unreliable.
		On the other hand,
		the asymptotically distribution free (ADF) estimator does not rely on any distribution assumption but cannot demonstrate its efficiency advantage with small and modest sample sizes.
		The methods which adopt misspecified loss functions including ridge GLS (RGLS) can provide better estimates and inferences than the normal theory based methods and the ADF estimator in some cases.
		We propose a distributionally weighted least squares (DLS) estimator,
		and expect that it can perform better than the existing generalized least squares,
		because it combines normal theory based and ADF based generalized least squares estimation.
		Computer simulation results suggest that model-implied covariance based DLS (DLSM) provided relatively accurate and efficient estimates in terms of RMSE.
		In addition,
		the empirical standard errors,
		the relative biases of standard error estimates,
		and the Type I error rates of the Jiang-Yuan rank adjusted model fit test statistic (TJY) in DLSM were competitive with the classical methods including ML, GLS, and RGLS.
		The performance of DLSM depends on its tuning parameter a.
		We illustrate how to implement DLSM and select the optimal a by a bootstrap procedure in a real data example.
	},
		
}

@Comment{jabref-meta: databaseType:biblatex;}
